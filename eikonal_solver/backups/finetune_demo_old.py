"""
Finetune SAMRoute map_decoder on Gen_dataset_V2/Gen_dataset (multi-image batch training).

Optimized for multi-GPU (DDP), large batch, TF32, cached features, high-throughput data loading.
"""
import argparse
import os
import torch

# å¼€å¯ TF32ï¼š4090 ç­‰ Ada æ¶æ„ä¸ŠçŸ©é˜µä¹˜æ³•å¯åŠ é€Ÿ 2~3 å€ï¼Œå‡ ä¹æ— ç²¾åº¦æŸå¤±
torch.set_float32_matmul_precision("high")

try:
    import lightning.pytorch as pl
    from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor
    from lightning.pytorch.loggers import TensorBoardLogger
except ImportError:
    import pytorch_lightning as pl
    from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
    from pytorch_lightning.loggers import TensorBoardLogger

from model import SAMRoute
from dataset import build_dataloaders

# ==========================================
# 1. è®­ç»ƒé…ç½®
# ==========================================
class TrainConfig:
    def __init__(self):
        self.SAM_VERSION = 'vit_b'
        self.PATCH_SIZE = 512
        self.NO_SAM = False
        self.USE_SAM_DECODER = False
        self.ENCODER_LORA = False
        self.FREEZE_ENCODER = True   # ç»å¯¹å†»ç»“ SAM Encoderï¼Œåªè®­ç»ƒ Decoder
        self.FOCAL_LOSS = False
        self.TOPONET_VERSION = 'default'

        _SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
        _PROJECT_ROOT = os.path.normpath(os.path.join(_SCRIPT_DIR, ".."))
        self.SAM_CKPT_PATH = os.path.join(_PROJECT_ROOT, "sam_road_repo", "sam_ckpts", "sam_vit_b_01ec64.pth")

        # è·¯ç”±/æŸå¤±é…ç½®
        self.ROUTE_COST_MODE = 'add'
        self.ROAD_POS_WEIGHT = 13.9
        self.ROAD_DICE_WEIGHT = 0.5
        self.ROAD_DUAL_TARGET = False

        self.ROUTE_LAMBDA_SEG = 1.0
        self.ROUTE_LAMBDA_DIST = 0.0
        self.BASE_LR = 5e-4  # é…åˆ batch_size=16ï¼Œè¾ƒ 4 æ—¶é€‚å½“æ”¾å¤§
        self.ENCODER_LR_FACTOR = 0.1   # configure_optimizers éœ€æ­¤å±æ€§
        self.LR_MILESTONES = [150] 

    def get(self, key, default):
        return getattr(self, key, default)

# ==========================================
# 2. è®­ç»ƒæµç¨‹ (ä½¿ç”¨ Lightning Trainer)
# ==========================================
def train(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"å‡†å¤‡è®­ç»ƒ... æ£€æµ‹åˆ°è®¾å¤‡: {device}")

    _SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    _PROJECT_ROOT = os.path.normpath(os.path.join(_SCRIPT_DIR, ".."))

    data_root = args.data_root if os.path.isabs(args.data_root) else os.path.join(_PROJECT_ROOT, args.data_root)
    PRETRAINED_CKPT = args.pretrained_ckpt if os.path.isabs(args.pretrained_ckpt) else os.path.join(_PROJECT_ROOT, args.pretrained_ckpt)
    output_dir = args.output_dir if os.path.isabs(args.output_dir) else os.path.join(_PROJECT_ROOT, args.output_dir)
    ckpt_dir = os.path.join(output_dir, "checkpoints")

    if not os.path.isdir(data_root):
        raise FileNotFoundError(f"æ•°æ®é›†æ ¹ç›®å½•ä¸å­˜åœ¨: {data_root}")
    os.makedirs(ckpt_dir, exist_ok=True)

    config = TrainConfig()
    if args.lr is not None:
        config.BASE_LR = args.lr
    model = SAMRoute(config)

    # æ‰‹åŠ¨å†»ç»“æœ¬é˜¶æ®µä¸å‚ä¸ Loss çš„å‚æ•°ï¼Œæ»¡è¶³ DDP æ ¡éªŒï¼Œä»è€Œä½¿ç”¨æ ‡å‡† ddp è€Œéé¾Ÿé€Ÿ find_unused_parameters
    if config.FREEZE_ENCODER:
        for p in model.image_encoder.parameters():
            p.requires_grad = False
    if config.ROUTE_LAMBDA_DIST == 0.0:
        model.cost_log_alpha.requires_grad = False
        model.cost_log_gamma.requires_grad = False
        model.eik_gate_logit.requires_grad = False
        for p in model.topo_net.parameters():
            p.requires_grad = False

    # 1. å®‰å…¨åŠ è½½é¢„è®­ç»ƒæƒé‡
    if os.path.isfile(PRETRAINED_CKPT):
        print(f"åŠ è½½é¢„è®­ç»ƒæƒé‡: {PRETRAINED_CKPT}")
        ckpt = torch.load(PRETRAINED_CKPT, map_location='cpu', weights_only=False)
        state_dict = ckpt.get("state_dict", ckpt)
        clean_state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
        model.load_state_dict(clean_state_dict, strict=False)
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ {PRETRAINED_CKPT}ï¼Œä»éšæœº Decoder å¼€å§‹è®­ç»ƒã€‚")

    # 2. æ„å»º DataLoader
    # use_cached_features=True æ—¶è·³è¿‡ Encoder è®¡ç®—ï¼Œç”¨é¢„å­˜ .npy ç‰¹å¾ï¼Œå¯ 10x+ æé€Ÿ
    print("æ­£åœ¨æ„å»ºæ•°æ®é›†å¹¶åŠ è½½åˆ°å†…å­˜...")
    train_loader, val_loader = build_dataloaders(
        root_dir=data_root,
        patch_size=config.PATCH_SIZE,
        batch_size=args.batch_size,
        num_workers=args.workers,
        include_dist=False,
        val_fraction=args.val_fraction,
        samples_per_region=args.samples_per_region,
        use_cached_features=args.use_cached_features,
        preload_to_ram=args.preload_to_ram,
        road_dilation_radius=args.road_dilation_radius,
    )

    # 3. é…ç½® Lightning å›è°ƒï¼ˆä»…ä¿ç•™ best + lastï¼Œå›ºå®šæ–‡ä»¶åé¿å…ç´¯ç§¯ï¼‰
    checkpoint_callback = ModelCheckpoint(
        dirpath=ckpt_dir,
        filename='best',                    # å›ºå®šå best.ckptï¼Œè¦†ç›–æ—§æ–‡ä»¶
        save_top_k=1,
        monitor='val_seg_loss',
        mode='min',
        save_last=True,
        every_n_epochs=1,                   # æ¯ epoch æ£€æŸ¥ä¸€æ¬¡
    )
    lr_monitor = LearningRateMonitor(logging_interval='epoch')

    # è®­ç»ƒæ—¥å¿—ï¼ˆTensorBoardï¼‰
    tb_logger = TensorBoardLogger(save_dir=output_dir, name="tensorboard", version=None)

    # 4. å¯åŠ¨ Trainer
    use_gpu = torch.cuda.is_available()
    n_gpus = torch.cuda.device_count() if use_gpu else 0
    devices = args.devices if args.devices is not None else (n_gpus or 1)
    use_ddp = use_gpu and devices > 1
    precision = "16-mixed" if use_gpu else "32"
    # å·²æ‰‹åŠ¨å†»ç»“ encoder/eikonal/topoï¼Œå¯ç”¨æ ‡å‡† ddpï¼ˆfind_unused æ˜¯æ€§èƒ½æ€æ‰‹ï¼‰
    strategy = "ddp" if use_ddp else "auto"
    trainer = pl.Trainer(
        max_epochs=args.epochs,
        accelerator="gpu" if use_gpu else "cpu",
        devices=devices,
        strategy=strategy,
        precision=precision,
        logger=tb_logger,
        callbacks=[checkpoint_callback, lr_monitor],
        log_every_n_steps=50,           # å‡å°‘ step çº§æ—¥å¿—
        val_check_interval=0.25,       # æ¯ 25% çš„ train åšä¸€æ¬¡ valï¼Œåˆ†æ•£å¼€é”€
        enable_progress_bar=True,
        enable_model_summary=False,     # è·³è¿‡å¯åŠ¨æ—¶çš„ model summary
    )
    if use_ddp:
        print(f"ä½¿ç”¨ {devices} å¼  GPU è¿›è¡Œ DDP åˆ†å¸ƒå¼è®­ç»ƒ")

    print("\nğŸš€ å¼€å§‹æ­£å¼å¾®è°ƒè®­ç»ƒ...")
    trainer.fit(model, train_loader, val_loader)
    print(f"\nâœ… è®­ç»ƒå®Œæˆã€‚æœ€ä½³æƒé‡å·²ä¿å­˜åœ¨: {ckpt_dir}")
    print(f"   è®­ç»ƒæ›²çº¿: tensorboard --logdir {os.path.join(output_dir, 'tensorboard')} --port 6006")

# ==========================================
# 3. å‘½ä»¤è¡Œå‚æ•°
# ==========================================
def parse_args():
    p = argparse.ArgumentParser(
        description="SAMRoute finetune â€” å¤šå›¾æ‰¹é‡æ­£å¼è®­ç»ƒ (æ”¯æŒ DDPã€TF32ã€cached features)",
        epilog="ç¤ºä¾‹: python finetune_demo.py --batch_size 16 --workers 8 --epochs 50"
    )
    p.add_argument("--data_root", default="Gen_dataset_V2/Gen_dataset", help="æ•°æ®é›†æ ¹ç›®å½•")
    p.add_argument("--pretrained_ckpt", default="checkpoints/cityscale_vitb_512_e10.ckpt", help="é¢„è®­ç»ƒ SAM-Road æƒé‡è·¯å¾„")
    p.add_argument("--output_dir", default="training_outputs/finetune_demo", help="è¾“å‡ºç›®å½•")
    p.add_argument("--epochs", type=int, default=50, help="è®­ç»ƒè½®æ•°")
    p.add_argument("--batch_size", type=int, default=32, help="batch sizeï¼Œcached æ¨¡å¼æ˜¾å­˜å ç”¨ä½å¯å¼€ 32~64")
    p.add_argument("--lr", type=float, default=None, help="å­¦ä¹ ç‡ï¼Œé»˜è®¤ 5e-4 (é…åˆ batch 16)")
    p.add_argument("--val_fraction", type=float, default=0.1, help="éªŒè¯é›†åŸå¸‚å æ¯” (0~1)")
    p.add_argument("--samples_per_region", type=int, default=50, help="æ¯åŒºåŸŸæ¯ epoch é‡‡æ ·æ•°")
    p.add_argument("--road_dilation_radius", type=int, default=3, help="å½’ä¸€åŒ– mask åŠå¾„")
    p.add_argument("--workers", type=int, default=4, help="DataLoader workersï¼Œpreload æ—¶ 4 è¶³å¤Ÿ")
    p.add_argument("--devices", type=int, default=None, help="GPU æ•°é‡ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹å…¨éƒ¨")
    p.add_argument("--use_cached_features", action="store_true", help="ä½¿ç”¨é¢„è®¡ç®— samroad_feat_full_*.npy è·³è¿‡ Encoder")
    p.add_argument("--no_cached_features", action="store_true", help="å…³é—­ cached featuresï¼Œå§‹ç»ˆè·‘ Encoder")
    p.add_argument("--no_preload", action="store_true", help="å…³é—­ preload_to_ram")
    p.add_argument("--fast", action="store_true", help="å¿«é€Ÿæ¨¡å¼ï¼šå•å¡ batch32 workers4ï¼Œä¾¿äºè°ƒè¯•")
    args = p.parse_args()
    args.preload_to_ram = not args.no_preload
    args.use_cached_features = args.use_cached_features and not args.no_cached_features
    if args.fast:
        args.devices = args.devices or 1
        args.batch_size = 32
        args.workers = 4
        args.use_cached_features = True
        print("âš ï¸ --fast: å•å¡ batch=32 workers=4 use_cached_features=True")
    return args

if __name__ == "__main__":
    args = parse_args()
    train(args)