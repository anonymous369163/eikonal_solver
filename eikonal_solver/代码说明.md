我已经把“\*\*Prob→Cost 加一个轻量 CNN（残差/对数域乘性修补）\*\*”完整落到代码里，并且把你之前遇到的 \*\*`(1-p)^gamma` 在 p=1 时导致 NaN 梯度\*\*的问题也一并做了“模型侧兜底”（在 cost 映射里强制把 `prob` clamp 到 `(eps,1-eps)`）。



下面是两份\*\*最终改进后的可直接用代码\*\*（已通过语法检查）：



\* ✅ \*\*模型文件（加入 ResidualCostNet + 数值稳定性修复）\*\*

&nbsp; \[下载 model\_multigrid\_costnet.py](sandbox:/mnt/data/model\_multigrid\_costnet.py)



\* ✅ \*\*整图 fullmap 训练/测试脚本（默认启用 cost net + 加正则项防作弊）\*\*

&nbsp; \[下载 gradcheck\_route\_loss\_v2\_multigrid\_fullmap\_costnet.py](sandbox:/mnt/data/gradcheck\_route\_loss\_v2\_multigrid\_fullmap\_costnet.py)



---



\## 你需要怎么用（两种方式，选一种）



\### 方式 A（推荐）：直接替换原文件



1\. 用 `model\_multigrid\_costnet.py` 替换你工程里的 `model\_multigrid.py`

2\. 用 `gradcheck\_route\_loss\_v2\_multigrid\_fullmap\_costnet.py` 替换原 `gradcheck\_route\_loss\_v2\_multigrid\_fullmap.py`



这样你原来所有 `from model\_multigrid import ...` 的脚本都不用改。



\### 方式 B：不替换，只改 import



如果你不想覆盖原文件，那么：



\* 在你要用 cost net 的脚本里把

&nbsp; `from model\_multigrid import ...`

&nbsp; 改成

&nbsp; `from model\_multigrid\_costnet import ...`



---



\## 改进点概览（你会看到“可训练参数变多”）



\### 1) 在 `SAMRoute` 里新增一个轻量 CNN：ResidualCostNet



\* 输入：`prob`（可选再拼 `(y,x)` 坐标通道）

\* 输出：`delta\_log\_cost`（用 `tanh` 限幅，再乘 `delta\_scale`）

\* 融合：`cost = base\_cost \* exp(delta\_log\_cost)`

&nbsp; ✅ 永远正值，不会让 Eikonal 崩

&nbsp; ✅ 初始是 identity（最后一层 zero-init），不会破坏你现有结果



对应新配置项（都已加入）：



\* `ROUTE\_COST\_NET`（默认 \*\*True\*\*，在 fullmap\_costnet 脚本里）

\* `ROUTE\_COST\_NET\_CH`（默认 8）

\* `ROUTE\_COST\_NET\_USE\_COORD`（默认 False）

\* `ROUTE\_COST\_NET\_DELTA\_SCALE`（默认 0.75）



\### 2) 数值稳定性：在 cost 映射里强制 `prob = clamp(eps, 1-eps)`



这能避免你之前日志里那种：



\* `cost\_log\_gamma grad = nan`

\* `map\_decoder grad = nan`

\* `road\_prob\_grad\_norm = nan`

&nbsp; 的经典来源（`log(0)` / `0 \* -inf`）。



\### 3) fullmap 脚本里加入“防作弊正则”



因为 distance 监督是线积分型 inverse problem，很容易“全图降 cost”来匹配距离，我在脚本里加了两项可开关的正则：



\* `--lambda\_cost\_reg`（默认 1e-3）：`mean(delta^2) + mean(delta)^2`（抑制全局偏置）

\* `--lambda\_cost\_tv`（默认 0.0）：TV-L1（可选让 residual 更平滑）

\* `--reg\_on\_coarse`：可选也约束 coarse-grid residual（multigrid 场景下更稳）



---



\## 推荐的起步命令（整图训练距离）



如果你是 fullmap + multigrid + tube 这条路线，先这样跑（稳）：



```bash

python gradcheck\_route\_loss\_v2\_multigrid\_fullmap\_costnet.py \\

&nbsp; --ckpt /path/to/your\_finetuned.ckpt \\

&nbsp; --tif /path/to/crop\_xxx.tif \\

&nbsp; --sample\_from\_npz --p\_count 20 --k\_targets 4 \\

&nbsp; --multigrid --mg\_factor 4 --tube\_roi \\

&nbsp; --eik\_iters 40 --downsample 4 \\

&nbsp; --lambda\_dist 1.0 --steps 20 --lr 1e-4 \\

&nbsp; --lambda\_cost\_reg 1e-3 --lambda\_cost\_tv 0.0 \\

&nbsp; --save\_debug /tmp/fullmap\_costnet --vis\_full\_route

```



如果你想做 ablation（关闭 cost net）：



```bash

... --no\_cost\_net

```



---



如果你把你当前工程里 \*\*tube ROI / multigrid 的 model\_multigrid.py\*\*还有额外本地改动（例如你后来加的某些 debug meta 输出），我也可以按你本地版本再做一次“最小差异合并”，保证不会丢你自己的改动。



